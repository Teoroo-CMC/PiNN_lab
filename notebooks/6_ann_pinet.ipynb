{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atomic Neural Networks (continued)\n",
    "\n",
    "## Drawbacks of representation-based approach\n",
    "\n",
    "\n",
    "PiNN takes a different approach here. Instead of defining an unique \n",
    "representation for atomic environments, we use neural networks to \n",
    "find that representation for us. \n",
    "\n",
    "Rather than finding a good representation of structures, we try to find \n",
    "a good arrangement of neural networks, so that a representation of \n",
    "atomic structures can be generated.\n",
    "\n",
    "To explain how this is done, we first introduce the convolutional neural \n",
    "networks, which is a class of methods closely related to our approach.\n",
    "\n",
    "## Convolutional neural networks\n",
    "\n",
    "![](https://i.stack.imgur.com/mFBCV.png)\n",
    "\n",
    "Convolution neural networks works for images, which are pixels of color data.\n",
    "Prediction of images faces similar challenges as atoms. Images comes with \n",
    "different size and shapes, but we know that the information is somehow localized.\n",
    "\n",
    "![](https://www.codespeedy.com/wp-content/uploads/2019/05/convolutional-layers-of-an-image-Deep-learning-Machine-learning.jpg)\n",
    "\n",
    "The convolution neural network tackled the image recognition problem by using \n",
    "neural networks as \"filters\", a function that maps a patch of image to some \n",
    "local information (is there a blue line, is there a circle, etc?) and then \n",
    "the local information is fed into another filter, and so forth...\n",
    "\n",
    "The each \"filter\" here is a small neural network that maps a patch of image\n",
    "to a flexible local prediction. The **intuition** of how this works, is that \n",
    "each filter may predict some simple features about the small patch. \n",
    "By stacking them we are able to construct slightly more complex predictions:\n",
    "two circles next to each other might be two eyes. \n",
    "And we will be able to make very complex predictions simply by stacking \n",
    "simple local rules.\n",
    "\n",
    "The intuition can be verified by visualizing the activations of the neural network\n",
    "at different layers.\n",
    "![](https://gradientscience.org/assets/rf1_images/visualization.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph convolution networks\n",
    "\n",
    "One can apply a similar intuition to atomic neural networks. \n",
    "What we have to do then is to find a way to construct a flexible way to make local predictions\n",
    "Given a structure of atoms, we use neural networks to construct interactions between atoms,\n",
    "using atomic properties (like elements) as inputs. Then the interaction is summed up to the \n",
    "central atoms, to serve a a new set of properties.\n",
    "\n",
    "![](https://pubs.acs.org/na101/home/literatum/publisher/achs/journals/content/jcisd8/2020/jcisd8.2020.60.issue-3/acs.jcim.9b00994/20200316/images/medium/ci9b00994_0002.gif)\n",
    "\n",
    "Instead of designing the features and predicting the result at once, \n",
    "one predict the low-level features of the atom at first (bond order, polarization, etc)\n",
    "and get the proceed to more complex features (hybridization, conjugate, etc) with concatenated layers.\n",
    "And we finally make the prediction with the refined features.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
