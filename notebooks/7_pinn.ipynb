{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting molecular properties with PiNN\n",
    "\n",
    "[PiNN](https://github.com/Teoroo-CMC/PiNN) is a Python library we have developed to build atomic neural networks. We implemented both the GCNN based network (called PiNet) and the representation based \n",
    "BPNN.\n",
    "\n",
    "In this notebook we'll demonstrate how to predict properties of molecules with PiNN.\n",
    "\n",
    "Here we use the QM9 dataset [doi:10.6084/m9.figshare.978904](https://figshare.com/collections/Quantum_chemistry_structures_and_properties_of_134_kilo_molecules/978904).\n",
    "A collection of quantum chemical calculations of 134 kilo organic molecules, which is a subset of the GDB-17 chemical universe of 166 billion organic molecules.\n",
    "\n",
    "\n",
    "### A table of the properties\n",
    "\n",
    "   |Property|Unit       |Description|\n",
    "   |:-------|:----------|:-------------|\n",
    "   |A       |GHz        |Rotational constant A|\n",
    "   |B       |GHz        |Rotational constant B|\n",
    "   |C       |GHz        |Rotational constant C|\n",
    "   |mu      |Debye      |Dipole moment|\n",
    "   |alpha   |Bohr^3     |Isotropic polarizability|\n",
    "   |homo    |Hartree    |Energy of Highest occupied molecular orbital (HOMO)|\n",
    "   |lumo    |Hartree    |Energy of Lowest occupied molecular orbital (LUMO)|\n",
    "   |gap     |Hartree    |Gap, difference between LUMO and HOMO|\n",
    "   |r2      |Bohr^2     |Electronic spatial extent|\n",
    "   |zpve    |Hartree    |Zero point vibrational energy|\n",
    "   |U0      |Hartree    |Internal energy at 0 K|\n",
    "   |U       |Hartree    |Internal energy at 298.15 K|\n",
    "   |H       |Hartree    |Enthalpy at 298.15 K|\n",
    "   |G       |Hartree    |Free energy at 298.15 K|\n",
    "   |Cv      |cal/(mol K)|Heat capacity at 298.15 K|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing requirements\n",
    "\n",
    "To run this module you need to install PiNN and PiNNboard: the libraries we developed for building atomic neural networks and to visualize them. To do so, run the next block.\n",
    "\n",
    "The block also downloads a copy of the QM9 dataset to your runtime.\n",
    "*We re-centered all the properties to zero to avoid numerical difficulties during training, you are provided 20000 data points for you to run the training, and 20000 more to run the validation/testing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide some noisy warnings before we start\n",
    "import warnings, logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings('ignore', 'Converting sparse IndexedSlices')\n",
    "!pip install tensorboard==2.4\n",
    "!pip install --quiet git+https://github.com/yqshao/PiNN.git@TF2\n",
    "!pip install --quiet git+https://github.com/yqshao/PiNNboard.git@TF2\n",
    "!wget -nv https://raw.githubusercontent.com/yqshao/PiNNLab/master/resources/qm9_{train,test}.{yml,tfr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn.io import load_tfrecord, sparse_batch\n",
    "\n",
    "train_set = load_tfrecord('qm9_train.yml')\n",
    "vali_set = load_tfrecord('qm9_test.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow, a dataset can be seen as an \"iterator\"\n",
    "of datum, you can write like\n",
    "\n",
    "``` Python\n",
    "for data in dataset:\n",
    "    ...\n",
    "```\n",
    "\n",
    "To see only one of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in train_set:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can see that one data is a dictionary with all the properties we have, as tensors.  \n",
    "\n",
    "To see it more clearly, run this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for training\n",
    "\n",
    "Before the training, we need to label that data so that TensorFlow knows that we want to train. The following code block labels the \"U0\" as the training target\n",
    "and batches the dataset. Make sure you know what it does, later you can reuse the code to select other properties to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(data):\n",
    "    x = data\n",
    "    y = data['U0']\n",
    "    return x, y\n",
    "\n",
    "train = train_set.apply(sparse_batch(30)).map(label_data)\n",
    "vali = vali_set.apply(sparse_batch(30)).map(label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining an atomic neural network\n",
    "\n",
    "### PiNet\n",
    "\n",
    "PiNet is the GCNN architectures implemented in PiNN. Its structure is controlled by the\n",
    "four neural networks, each aiming for different purposes. \n",
    "\n",
    "- PI Layers transforms the atomic properties of a pair to a pairwise interaction\n",
    "- II Layers transforms pairwise interactions to pairwise interactions\n",
    "- PP Layers transforms atom-wise properties to atom-wise properties\n",
    "- Output Layers performs the actual prediction\n",
    "\n",
    "![image.png](https://github.com/yqshao/PiNNLab/raw/master/resources/pinet.png)\n",
    "\n",
    "The networks are defined by the structure of four feed-forward neural networks, each is specified by a \n",
    "list of hidden units.\n",
    "- The `depth` parameter controls how many times this \"Graph Convoluton Operation\" is repeated\n",
    "\n",
    "### The `out_pool` parameter\n",
    "\n",
    "Recall that both BPNN and PiNet make predictions on atoms, it remains a problem how we make molecular predictions from atomic ones. Four options are available for both network:\n",
    "\n",
    "- `'sum'`: sum over atomic predictions\n",
    "- `'min'`: minimum of atomic predictions\n",
    "- `'max'`: maximum of atomic predictions\n",
    "- `'avg'`: average of atomic predictions\n",
    "\n",
    "Depending on what you want to predict one may choose one of them, for example, when predicting total energies it makes sense to sum up atomic predictions, but for HOMO it might be a better idea to use `'max'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting an atomic neural network\n",
    "\n",
    "With PiNN you can create atomic neural networks as Keras models, define and fit a PiNet with the following code block.\n",
    "\n",
    "We used a relatively small model here and trained or less steps \n",
    "for the purpose of demonstration, feel free to increase them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn.networks.pinet import PiNet\n",
    "\n",
    "pinet = PiNet(pp_nodes=[6], ii_nodes=[6,6], pi_nodes=[6,6], out_nodes=[3], \n",
    "              depth=2, out_pool='sum')\n",
    "pinet.compile(optimizer='Adam', loss='MAE')\n",
    "pinet.fit(train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a network \n",
    "\n",
    "PiNN provides a tool called PiNNboard to visualize the activation and weights of an ANN.\n",
    "To use PiNNboard, you create a callback just like the case of TensorBoard.\n",
    "\n",
    "Here we visualize the neural network with the first 30 samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard_plugin_pinnboard.summary import PiNNBoardCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "logdir = 'logs/PiNet'\n",
    "tb_cbk = TensorBoard(log_dir=logdir, write_graph=True)\n",
    "pb_cbk = PiNNBoardCallback(logdir, train_set.apply(sparse_batch(30)))\n",
    "\n",
    "pinet = PiNet(pp_nodes=[6], ii_nodes=[6,6], pi_nodes=[6,6], out_nodes=[3], \n",
    "              depth=2, out_pool='sum')\n",
    "\n",
    "pinet.compile(optimizer='Adam', loss='MAE')\n",
    "pinet.fit(train, epochs=3, validation_data=vali, callbacks=[tb_cbk, pb_cbk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the next block. A TensorBoard will start and you can select your network\n",
    "to visualize it. \n",
    "\n",
    "- Try to understand what the connections mean.\n",
    "- Move the slider to see how the weights and activations changes during the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs --samples_per_plugin PiNNboard=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK**\n",
    "\n",
    "Pick one of the properties in the QM9 dataset to predict\n",
    "\n",
    "- Train a PiNet for the select property\n",
    "- Visualized the trained model using TensorBoard\n",
    "- Change the `out_pool` parameter to see its impact\n",
    "- Try to improve the performance by tweaking the network parameters\n",
    "\n",
    "Answer the questions\n",
    "    \n",
    "- Does the activations of nodes make sense?\n",
    "  - Do they distinguish atoms meaningfully?\n",
    "  - Can you recognize any interaction they learnt?\n",
    "- How does `out_pool` affect your prediction?\n",
    "- What is your best training performance, how do you get it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reference this is the mean absolute error of different machine learning models' U0 prediction\n",
    "on the QM9 dataset, as a function of training data (we are using  $2\\times 10^4$ samples from the dataset here), can you \n",
    "find your position in it?\n",
    "\n",
    "![image.png](https://github.com/yqshao/PiNNLab/raw/master/resources/qm9_benchmarks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  BPNN\n",
    "\n",
    "Another network implemented in PiNN is the Behler Parrinello Neural Network (BPNN).\n",
    "The network is specified by the setup of symmetry functions and element specified \n",
    "neural networks. Below is an example setup. You can read more about the definition \n",
    "of symmetry functions in this [paper](https://onlinelibrary.wiley.com/doi/full/10.1002/qua.24890) and in the [PiNN documentation](https://teoroo-pinn.readthedocs.io/en/latest/networks/bpnn.html).\n",
    "\n",
    "- Try to run the following block which will train a BPNN with a minimal set of \n",
    "   symmetry functions.\n",
    "- Visualize the network in PiNNboard and see the structure of BPNN.\n",
    "\n",
    "**BONUS:**\n",
    "can you find a good BPNN setup that predicts your molecular property well?\n",
    "- In the example we do not split the elements when we define the symmetry function,\n",
    "- you can improve this by tailoring the symmetry function for different (pairs) of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinn.networks import BPNN\n",
    "\n",
    "bpnn = BPNN(\n",
    "    sf_spec=[{'type':'G2', \n",
    "              'i': 'ALL', 'j': 'ALL', \n",
    "              'Rs': [1.,1.5,2.], 'eta': [0.2, 0.5, 1.0]}],\n",
    "    nn_spec={6: [3, 3, 3], 1: [3, 3, 3]} ,\n",
    "    out_pool='sum')\n",
    "\n",
    "logdir = 'logs/BPNN'\n",
    "tb_cbk = TensorBoard(log_dir=logdir, write_graph=True)\n",
    "pb_cbk = PiNNBoardCallback(logdir, train_set.apply(sparse_batch(30)))\n",
    "\n",
    "bpnn.compile(optimizer='Adam', loss='MAE')\n",
    "bpnn.fit(train, epochs=3, validation_data=vali, callbacks=[tb_cbk, pb_cbk])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
