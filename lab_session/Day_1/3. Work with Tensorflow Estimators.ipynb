{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tensorflow estimators\n",
    "\n",
    "Estimator are tensorflow's high-level api for creating neural network models.\n",
    "A estimator provides easy interface for training, evaluating and predicting \n",
    "with neural networks.\n",
    "\n",
    "A main reason to use estimator is to avoid writing your own code for training\n",
    "and focus on the network structure. \n",
    "\n",
    "A estimator can be easily trained on different resources (CPU, GPU, Cloud, etc）\n",
    "\n",
    "## 3.1 Define an Estimator - dataset\n",
    "\n",
    "The first step to use estimators is to translate the data to something\n",
    "it could understand.\n",
    "\n",
    "Tensorflow dataset can be easily created from numpy arrays:\n",
    "\n",
    "```python\n",
    "tf.data.Dataset.from_tensor_slices({\"x\": x_train, \"y\": y_train})\n",
    "```\n",
    "\n",
    "However, estimator expect the dataset to be a function that returns \n",
    "a dataset, instead of a dataset itself.\n",
    "\n",
    "The following code creates datasets of {x,y} values.\n",
    "In addition, the dataset is shuffled and batched to 5-element batches.  \n",
    "The use of mini-batches like this is common in the training of neural networks，so that the gradient can be updated by calculating only part of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x_train = np.linspace(0, 10,1000)[:,np.newaxis]\n",
    "y_train = np.sin(x_train*2)\n",
    "def dataset():\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        {\"x\": x_train, \"y\": y_train}).repeat().shuffle(1000).batch(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows a minibatch of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = dataset().make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "sess = tf.Session()\n",
    "sess.run(next_element)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an Estimator - model function\n",
    "\n",
    "The estimator is defined by a model function.  \n",
    "\n",
    "\n",
    "The input parameters of the model function is fixed.  \n",
    "The  model function should return corresponding `EstimatorSpec` according to the `mode` parameter.\n",
    "\n",
    "In this simple example, the model function uses two densely connected layers of neurons and outputs a single value.\n",
    "The model function returns the prediction when `mode` is `PREDICT`, and returns a AdamOptimizer when `mode` is `TRAIN`.  \n",
    "\n",
    "(Adam is a somehow improved version of gradient descent, again, we will not focus on the details about the optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    x = features['x']\n",
    "    \n",
    "    # This defines a neural network with three hidden layers\n",
    "    hidden1 = tf.layers.dense(x,       50, activation='tanh')\n",
    "    hidden2 = tf.layers.dense(hidden1, 50, activation='tanh')\n",
    "    hidden3 = tf.layers.dense(hidden2, 50, activation='tanh')\n",
    "    # The output node do not have a activation function,\n",
    "    # so that the output value is not constrained\n",
    "    y_pred = tf.layers.dense(hidden3, 1)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        y = features['y']\n",
    "        loss = tf.losses.mean_squared_error(y, y_pred)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "        \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = y_pred\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple neural network with Estimator\n",
    "\n",
    "The estimator can then be created with the model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the model_dir specifies where the training data is saved\n",
    "# Change the directory when you try out different parameters\n",
    "estimator = tf.estimator.Estimator(model_dir=\"simple_estimator\", model_fn=model_fn) \n",
    "estimator.train(input_fn=dataset, max_steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the estimator is to predict somehow not straight forward.\n",
    "It requires you to provide again a dataset for prediction.\n",
    "Use the following code to see your fitting results.\n",
    "\n",
    "You can also open a tensorboard to see how how the learning curve goes.\n",
    "Adjust your parameters accordingly to see how things change.  \n",
    "To use tensorboard, go back to the directory page, and click New->Tensorboad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_pred = np.linspace(0,10,1000)[:,np.newaxis]\n",
    "\n",
    "# Use the estimator to predict\n",
    "pred_ds = lambda: tf.data.Dataset.from_tensor_slices({'x':x_pred}).batch(1000)\n",
    "y_pred = estimator.predict(pred_ds, yield_single_examples=False)\n",
    "y_pred = next(y_pred)\n",
    "\n",
    "plt.plot(x_pred, y_pred, label='Prediction')\n",
    "plt.plot(x_train, y_train, label='Training')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is just a simplest demonstration of estimator.\n",
    "\n",
    "If you are after some challenge, you might want to implement some \n",
    "real-world applications of neural networks.\n",
    "\n",
    "See here for a collection of tutorial: https://github.com/GoogleCloudPlatform/tf-estimator-tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or get it with the following block\n",
    "!git clone https://github.com/GoogleCloudPlatform/tf-estimator-tutorials.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
